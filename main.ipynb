{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from easy_open_ai import get_answer_with_instruction # requires .env with OPENAI_API_KEY=\n",
    "from utils import normalize_string_to_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Takes Ukrainian Language Quiz \n",
    "\n",
    "In this file we will be making API calls to the [Chat Completion](https://platform.openai.com/docs/guides/text-generation/chat-completions-api) endpoints using [one funny library](https://github.com/anilev6/easy-open-ai) - a question for GPT with the instruction. \n",
    "\n",
    "A chosen model of ChatGPT answers the quiz, filling the data_\\{model\\}.json file, spawning a database of quiz results, that closely resembles the original quiz questions database, but is easier to visualize. \n",
    "\n",
    "For this task we will need *a quiz database* as .json with the specific structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gpt-3.5-turbo\"\n",
    "RAW_QUIZ_DB_PATH = \"project-1-at-2024-02-13-22-30-ff0f6dc4.json\"\n",
    "CLEAN_DATA_PATH = \"clean_data.json\"\n",
    "PROCESSED_DATA_PATH = normalize_string_to_filename(f\"data_{MODEL}\") + \".json\"\n",
    "REPORT_PATH = normalize_string_to_filename(f\"report_{MODEL}\") + \".txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first clean the data, leaving only the most necessary, and spawning a new clean .json as the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_json():\n",
    "\n",
    "    with open(RAW_QUIZ_DB_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    cleaned_data = []\n",
    "    for item in data:\n",
    "        cleaned_item = {\n",
    "            \"id\": item.get(\"id\"),\n",
    "            \"data\": {\n",
    "                \"context\": item.get(\"data\", {}).get(\"context\"),\n",
    "                \"question\": item.get(\"data\", {}).get(\"question\"),\n",
    "                \"options\": item.get(\"data\", {}).get(\"options\"),\n",
    "                \"answer\": item.get(\"data\", {}).get(\"answer\"),\n",
    "            },\n",
    "        }\n",
    "        cleaned_data.append(cleaned_item)\n",
    "\n",
    "    with open(CLEAN_DATA_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(cleaned_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# uncomment to launch\n",
    "# clean_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, having the clean data we are ready to poll ChatGPT.\n",
    "\n",
    "The results will be saved as the same .json, but with an extra key of the type 'model_answer' in 'data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_story(data: dict) -> str:\n",
    "    result = \"\\n\".join([data.get(\"context\", \"\"), data.get(\"question\", \"\")])\n",
    "    result += \"\\nOPTIONS\\n\"\n",
    "    result += \"\\n\".join(\n",
    "        [f\"{i} : {opt}\" for i, opt in enumerate(data.get(\"options\", []))]\n",
    "    )\n",
    "    result += \"\\nWhich option best fills the blank in the story?\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERAL_INSTRUCTION = \"\"\"\n",
    "This is a language quiz. \n",
    "Read the story with a blank and the answer options provided. \n",
    "Your task is to select the best option that completes the sentence \n",
    "instead of \"______\". \n",
    "Respond with the index of the correct option (e.g. number, 0).\n",
    "\"\"\"\n",
    "\n",
    "def process_item(item: dict):\n",
    "    data = item.get(\"data\")\n",
    "    options = data.get(\"options\")\n",
    "    question = get_story(data)\n",
    "    instruction = GENERAL_INSTRUCTION\n",
    "    response = get_answer_with_instruction(\n",
    "        question, instruction, chaos_coefficient=0, max_tokens=2000, model = MODEL\n",
    "    )\n",
    "    try:\n",
    "        result = options[int(response)]\n",
    "    except (ValueError, IndexError) as e:\n",
    "        try:\n",
    "            # insead of the number it returns the whole line\n",
    "            result = response.split(\":\")[1].strip()\n",
    "        except IndexError:\n",
    "            result = None\n",
    "\n",
    "    item[\"data\"][f\"{MODEL}_answer\"] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING Your request was malformed or missing some required parameters, such as a token or an input. Check the documentation for the specific API method you are calling and make sure you are sending valid and complete parameters.\n"
     ]
    }
   ],
   "source": [
    "def process_all_items():\n",
    "\n",
    "    with open(CLEAN_DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for i, item in enumerate(data):\n",
    "        if not item.get(f\"{MODEL}_answer\"):\n",
    "            try:\n",
    "                time.sleep(random.randint(1,7))\n",
    "                process_item(data[i])\n",
    "            except Exception as e:\n",
    "                print(f\"WARNING {e}\")\n",
    "                break\n",
    "\n",
    "    \n",
    "    with open(PROCESSED_DATA_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# process_all_items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of polling takes some time to be gentle with the API, but at the end we obtain the processed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "We will now count the success rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_model_right(data:dict):\n",
    "    answer = data.get(\"answer\")\n",
    "    model_answer = data.get(f\"{MODEL}_answer\")\n",
    "    if model_answer:\n",
    "        return 1 if answer == model_answer else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_and_sucsess():\n",
    "    with open(PROCESSED_DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        db = json.load(f)\n",
    "    total = [is_model_right(item.get(\"data\",{})) for item in db if is_model_right(item.get(\"data\",{})) is not None]\n",
    "    return len(total), sum(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    RESULTS_OBTAINED_FROM : project-1-at-2024-02-13-22-30-ff0f6dc4.json\n",
      "    RESULTS_OBTAINED_AT : 2024-02-14 04:12:41.205327\n",
      "    MODEL : gpt-3.5-turbo\n",
      "    TOTAL TASKS SOLVED : 559\n",
      "    SUCCESS : 304\n",
      "    RATE : 54 %\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def create_report():\n",
    "    total, suc = get_total_and_sucsess()\n",
    "\n",
    "    TEXT = f\"\"\"\n",
    "    RESULTS_OBTAINED_FROM : {RAW_QUIZ_DB_PATH}\n",
    "    RESULTS_OBTAINED_AT : {datetime.now()}\n",
    "    MODEL : {MODEL}\n",
    "    TOTAL TASKS SOLVED : {total}\n",
    "    SUCCESS : {suc}\n",
    "    RATE : {int(round(suc/total,2)*100)} %\n",
    "    \"\"\"\n",
    "    print(TEXT)\n",
    "\n",
    "    with open(REPORT_PATH, \"w\") as file:\n",
    "        file.write(TEXT)\n",
    "\n",
    "# create_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that the success rate is very low, **which strongly suggests a Ukrainian-speaking LLM needs further development.**\n",
    "\n",
    "For the further dive into the topic, one should proceed with implementing more experiments with different OpenAI models, as well as fine-tuned models with more Ukrainian literature fed to it, and compare the success rates.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
